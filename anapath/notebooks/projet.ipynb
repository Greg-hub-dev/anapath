{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openslide-bin in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (4.0.0.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openslide-python in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (1.4.1)\n",
      "Requirement already satisfied: Pillow in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from openslide-python) (9.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from opencv-python) (1.23.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ipython in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (8.5.0)\n",
      "Requirement already satisfied: backcall in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (2.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (5.5.0)\n",
      "Requirement already satisfied: stack-data in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (0.5.1)\n",
      "Requirement already satisfied: decorator in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (3.0.31)\n",
      "Requirement already satisfied: pickleshare in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from stack-data->ipython) (1.1.1)\n",
      "Requirement already satisfied: asttokens in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from stack-data->ipython) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six in /home/gregoire/.pyenv/versions/3.10.6/envs/anapath/lib/python3.10/site-packages (from asttokens->stack-data->ipython) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openslide-bin\n",
    "!pip install openslide-python\n",
    "!pip install opencv-python\n",
    "!pip install ipython\n",
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natsort==8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep natsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import des librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import preprocessing\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import openslide\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import csv\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "Min_SIZE_MB = 5 # Taille min par tuile (en Mo)\n",
    "tile_size_l = 4096\n",
    "tile_size_h = 2048  # Taille des tuiles\n",
    "level = 0  # Niveau de zoom OpenSlide (0 = max résolution)\n",
    "train_tumor_path = \"/mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/tumor\"\n",
    "train_normal_path = \"/mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/normal\"\n",
    "treated_tumor_path='/mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/tumor'\n",
    "treated_normal_path='/mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/normal'\n",
    "totreat_tumor_path = '/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/tumor'\n",
    "totreat_normal_path = '/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/normal'\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"  # Ajustez selon votre nombre de cœurs\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"16\"\n",
    "input_path = \"/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/tumor\" # / a la fin\n",
    "val_path='/mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/val'\n",
    "train_path='/mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de chargement du fichier mrxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load file mrxs and create a thumbnail\n",
    "def load_slide(file, source):\n",
    "    filename = f\"{file}.mrxs\"\n",
    "    path_to_slide = os.path.join(source,filename)\n",
    "    print(path_to_slide)\n",
    "    #with open(path_to_slide, \"r\") as f:\n",
    "    #   contenu = f.read()\n",
    "    slide = openslide.OpenSlide(path_to_slide)\n",
    "    # Récupérer une miniature pour analyse (taille réduite pour traitement rapide)\n",
    "    thumbnail = slide.get_thumbnail((1024, 2048))  # Ajuster la taille selon l’image\n",
    "    # Convertir en format OpenCV\n",
    "    thumbnail_np = np.array(thumbnail.convert(\"RGB\"))\n",
    "    return slide, thumbnail_np\n",
    "\n",
    "\n",
    "# Définir la zone (coordonnées x, y et taille du patch)\n",
    "#x, y = 50000, 110000  # Coordonnées de départ\n",
    "#width, height = 10000, 10000  # Taille de l'extrait\n",
    "\n",
    "## Extraire une région de l'image\n",
    "#region = slide.read_region((x, y), level=0, size=(width, height))\n",
    "## Convertir l'image pour affichage\n",
    "#region = region.convert(\"RGB\")\n",
    "#region.show()  # Ouvre l'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTION DE DEFINITION DES CONTOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contour_cells(thumbnail_np):\n",
    "    # Convertir l’image en HSV\n",
    "    hsv = cv2.cvtColor(thumbnail_np, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Définir les plages de couleur pour détecter le rose\n",
    "    lower_pink = np.array([110,0 , 0])   # Valeurs min HSV\n",
    "    upper_pink = np.array([180, 255, 255])  # Valeurs max HSV\n",
    "\n",
    "    # Masque des zones contenant du tissu\n",
    "    mask = cv2.inRange(hsv, lower_pink, upper_pink)\n",
    "\n",
    "    # Trouver les contours des zones roses\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Dessiner les contours sur l’image originale\n",
    "    contour_image = thumbnail_np.copy()\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher l’image avec les contours détectés\n",
    "    image_to_show = Image.fromarray(contour_image)\n",
    "\n",
    "    return image_to_show, mask, contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage du MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher le masque avec Matplotlib\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Masque du Tissu\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TROUVER DES CONTOURS DANS LES ZONES ROSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les contours des zones roses\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Dessiner les contours sur l’image originale\n",
    "contour_image = thumbnail_np.copy()\n",
    "cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l’image avec les contours détectés\n",
    "image_to_show = Image.fromarray(contour_image)\n",
    "plt.imshow(image_to_show)\n",
    "plt.title(\"Contour à découper\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 18:04:32.663411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-07 18:04:32.717951: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: []\n"
     ]
    }
   ],
   "source": [
    "# Pour TensorFlow\n",
    "import tensorflow as tf\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: False\n",
      "Nombre de GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# Pour PyTorch\n",
    "import torch\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de GPUs:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTION DE CUT DES LAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOUVELLE VERSION du CUT ##\n",
    "\n",
    "def slide_cut(slide, thumbnail_np, contours, filename,\n",
    "              output_path, level=0, tile_size_l=tile_size_l, tile_size_h=tile_size_h,\n",
    "              min_size_mb=Min_SIZE_MB, max_workers=8, global_csv_path=\"all_tiles_coordinates.csv\"):\n",
    "    \"\"\"\n",
    "    Découpe une lame (slide) en tuiles selon les contours détectés et sauvegarde leurs coordonnées.\n",
    "\n",
    "    Args:\n",
    "        slide: Objet OpenSlide contenant l'image de la lame\n",
    "        thumbnail_np: Miniature de la lame sous forme de tableau numpy\n",
    "        contours: Liste des contours détectés dans la miniature\n",
    "        filename: Nom du fichier source pour nommer les tuiles\n",
    "        output_path: Chemin de sortie pour sauvegarder les tuiles\n",
    "        level: Niveau de résolution à utiliser (défaut: 0, résolution maximale)\n",
    "        tile_size_l: Largeur des tuiles en pixels (défaut: 256)\n",
    "        tile_size_h: Hauteur des tuiles en pixels (défaut: 256)\n",
    "        min_size_mb: Taille minimale des tuiles en Mo (défaut: 0.01)\n",
    "        max_workers: Nombre de threads pour le traitement parallèle (défaut: 4)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (nombre_tuiles, temps_execution)\n",
    "    \"\"\"\n",
    "    # Assurer que le dossier de sortie existe\n",
    "    output_dir = Path(output_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # S'assurer que le nom de fichier est complet (avec le chemin d'accès)\n",
    "    # Stocker le nom de fichier complet (avec l'extension) pour la recherche ultérieure\n",
    "    full_filename = os.path.basename(filename)\n",
    "\n",
    "    # Vérifier si le fichier CSV global existe, sinon le créer avec des en-têtes\n",
    "    global_csv_path = os.path.join(output_path, global_csv_path)\n",
    "    csv_file_exists = os.path.isfile(global_csv_path)\n",
    "\n",
    "    # Préparer le fichier CSV avec les en-têtes\n",
    "    if not csv_file_exists:\n",
    "        with open(global_csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['slide_filename', 'tile_filename', 'contour_idx', 'x_original', 'y_original',\n",
    "                             'width', 'height', 'x_thumbnail', 'y_thumbnail',\n",
    "                             'w_thumbnail', 'h_thumbnail'])\n",
    "\n",
    "    # Calculer le facteur d'échelle entre la miniature et l'image originale\n",
    "    scale_x = slide.dimensions[0] / thumbnail_np.shape[1]\n",
    "    scale_y = slide.dimensions[1] / thumbnail_np.shape[0]\n",
    "\n",
    "    print(f\"Début du traitement du fichier {full_filename}...\")\n",
    "    start_time = time.time()  # Début du chronomètre\n",
    "\n",
    "    # Liste pour stocker les tâches de découpage\n",
    "    tiles_to_process = []\n",
    "\n",
    "    # Préparer la liste des tuiles à extraire\n",
    "    for contour_idx, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)  # Récupérer les coordonnées dans la miniature\n",
    "\n",
    "        # Convertir en coordonnées de l'image OpenSlide (grande taille)\n",
    "        x_slide = int(x * scale_x)\n",
    "        y_slide = int(y * scale_y)\n",
    "        w_slide = int(w * scale_x)\n",
    "        h_slide = int(h * scale_y)\n",
    "\n",
    "        # Récupérer les coordonnées de toutes les tuiles dans cette zone\n",
    "        for i in range(x_slide, x_slide + w_slide, tile_size_l):\n",
    "            for j in range(y_slide, y_slide + h_slide, tile_size_h):\n",
    "                # Ajouter cette tuile à la liste des tuiles à traiter\n",
    "                tile_info = {\n",
    "                    'position': (i, j),\n",
    "                    'contour_idx': contour_idx,\n",
    "                    'row': (i - x_slide) // tile_size_l,\n",
    "                    'col': (j - y_slide) // tile_size_h,\n",
    "                    'thumbnail_coords': (x, y, w, h)  # Coordonnées dans la miniature\n",
    "                }\n",
    "                tiles_to_process.append(tile_info)\n",
    "\n",
    "    def process_tile(tile_info):\n",
    "        \"\"\"Fonction qui traite une tuile individuelle\"\"\"\n",
    "        try:\n",
    "            i, j = tile_info['position']\n",
    "            contour_idx = tile_info['contour_idx']\n",
    "            row, col = tile_info['row'], tile_info['col']\n",
    "            x_thumb, y_thumb, w_thumb, h_thumb = tile_info['thumbnail_coords']\n",
    "\n",
    "            # Extraire la tuile\n",
    "            tile = slide.read_region((i, j), level, (tile_size_l, tile_size_h))\n",
    "\n",
    "            # Vérifier la taille avant sauvegarde\n",
    "            buffer = BytesIO()\n",
    "            tile.save(buffer, format=\"PNG\")\n",
    "            file_size_mb = len(buffer.getvalue()) / (1024 * 1024)\n",
    "\n",
    "            if file_size_mb > min_size_mb:\n",
    "                # Créer un nom de fichier plus informatif\n",
    "                tile_filename = f\"tile_{full_filename}_c{contour_idx}_r{row}_c{col}.png\"\n",
    "                tile_path = os.path.join(output_path, tile_filename)\n",
    "                tile.save(tile_path)\n",
    "\n",
    "                # Ajouter les coordonnées à la liste qui sera écrite dans le CSV\n",
    "                return [\n",
    "                    full_filename,            # Nom du fichier original\n",
    "                    tile_filename,        # Nom du fichier de la tuile\n",
    "                    contour_idx,          # Indice du contour\n",
    "                    i,                    # Position X dans l'image originale\n",
    "                    j,                    # Position Y dans l'image originale\n",
    "                    tile_size_l,          # Largeur de la tuile\n",
    "                    tile_size_h,          # Hauteur de la tuile\n",
    "                    x_thumb,              # Position X dans la miniature\n",
    "                    y_thumb,              # Position Y dans la miniature\n",
    "                    w_thumb,              # Largeur du contour dans la miniature\n",
    "                    h_thumb               # Hauteur du contour dans la miniature\n",
    "                ]\n",
    "\n",
    "            return None  # Indique que la tuile n'a pas été sauvegardée car trop petite\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement d'une tuile: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Traiter les tuiles en parallèle\n",
    "    saved_tiles_data = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(process_tile, tiles_to_process))\n",
    "        # Filtrer les résultats None (tuiles non sauvegardées)\n",
    "        saved_tiles_data = [result for result in results if result is not None]\n",
    "\n",
    "    # Écrire toutes les coordonnées dans le fichier CSV global\n",
    "    if saved_tiles_data:\n",
    "        with open(global_csv_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(saved_tiles_data)\n",
    "\n",
    "    # Calculer le temps d'exécution\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Fin du traitement du fichier {full_filename} en {execution_time:.2f} secondes\")\n",
    "    print(f\"{len(saved_tiles_data)} tuiles générées à partir du fichier {full_filename}\")\n",
    "    print(f\"Coordonnées ajoutées au fichier global: {global_csv_path}\")\n",
    "\n",
    "    return len(saved_tiles_data), execution_time, global_csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTION DE LA BOUCLE DE TRAITEMENT DES IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/normal/RB05762.mrxs\n",
      "Début du traitement du fichier RB05762...\n",
      "Fin du traitement du fichier RB05762 en 519.83 secondes\n",
      "687 tuiles générées à partir du fichier RB05762\n",
      "Coordonnées ajoutées au fichier global: /mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/normal/all_tiles_coordinates.csv\n",
      "/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/normal/RB05765.mrxs\n",
      "Début du traitement du fichier RB05765...\n",
      "Fin du traitement du fichier RB05765 en 127.28 secondes\n",
      "100 tuiles générées à partir du fichier RB05765\n",
      "Coordonnées ajoutées au fichier global: /mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/normal/all_tiles_coordinates.csv\n",
      "/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/normal/RB05780.mrxs\n",
      "Début du traitement du fichier RB05780...\n",
      "Fin du traitement du fichier RB05780 en 132.35 secondes\n",
      "125 tuiles générées à partir du fichier RB05780\n",
      "Coordonnées ajoutées au fichier global: /mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/normal/all_tiles_coordinates.csv\n",
      "/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/normal/RB05781.mrxs\n",
      "Début du traitement du fichier RB05781...\n",
      "Fin du traitement du fichier RB05781 en 186.89 secondes\n",
      "228 tuiles générées à partir du fichier RB05781\n",
      "Coordonnées ajoutées au fichier global: /mnt/c/Users/grego/Documents/Projet_ML/Data/Dataset/train/normal/all_tiles_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "## EXECUTION DU CUT SUR LE REPERTOIRE INPUT_PATH\n",
    "source = totreat_normal_path\n",
    "target = train_normal_path\n",
    "files = list(Path(source).glob('*.mrxs'))\n",
    "for file in files:\n",
    "    filename = file.name.split(sep=\".\")[0]\n",
    "    slide, thumbnail_np = load_slide(filename,source)\n",
    "    image, mask, contour = contour_cells(thumbnail_np)\n",
    "    #slide_cut(slide,thumbnail_np, contour,filename)\n",
    "    saved_tiles, execution_time, coords_file = slide_cut(slide, thumbnail_np, contour, filename, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTION DE SELECTION DE FICHIER ALEATOIRE POUR GENERATION DES ECHANTILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "def select_random_files_by_index(directory, num_files=15):\n",
    "    \"\"\"\n",
    "    Sélectionne aléatoirement un certain nombre de fichiers ayant le même indice.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Chemin vers le répertoire contenant les fichiers\n",
    "        num_files (int): Nombre de fichiers à sélectionner (défaut: 5)\n",
    "\n",
    "    Returns:\n",
    "        list: Liste des fichiers sélectionnés\n",
    "    \"\"\"\n",
    "    all_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "    # Extraire les indices des fichiers\n",
    "    indices = {}\n",
    "    for filename in all_files:\n",
    "        # Utiliser une expression régulière pour extraire l'indice\n",
    "        match = re.search(r'tile_([a-zA-Z0-9]+)_', filename)\n",
    "        if match:\n",
    "            index = match.group(1)\n",
    "            if index not in indices:\n",
    "                indices[index] = []\n",
    "            indices[index].append(filename)\n",
    "    print(indices)\n",
    "    # Dictionnaire pour stocker les résultats\n",
    "    selected_files_by_index = {}\n",
    "\n",
    "    # Pour chaque indice, sélectionner des fichiers aléatoires\n",
    "    for index, files in indices.items():\n",
    "        # Si suffisamment de fichiers sont disponibles pour cet indice\n",
    "        if len(files) >= num_files:\n",
    "            # Si suffisamment de fichiers sont disponibles, en sélectionner 5 aléatoirement\n",
    "            selected_files_by_index[index] = random.sample(files, num_files)\n",
    "        else:\n",
    "            # Si moins de 5 fichiers sont disponibles, prendre tous les fichiers\n",
    "            selected_files_by_index[index] = files\n",
    "\n",
    "    return selected_files_by_index\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    directory_path = train_normal_path  # Remplacez par votre chemin\n",
    "    selected_normal_files = select_random_files_by_index(directory_path)\n",
    "\n",
    "    print(f\"Fichiers sélectionnés avec le même indice:\")\n",
    "    for indice, file in selected_normal_files.items():\n",
    "        print(f\"{indice} : {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTION DEPLACANT LES FICHIERS NON SELECTIONNES DANS UN REPERTOIRE \"NOSELCT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "def move_unselected_files(directory, selected_files_dict):\n",
    "    \"\"\"\n",
    "    Déplace les fichiers non sélectionnés vers un répertoire 'noselect'.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Chemin vers le répertoire contenant les fichiers\n",
    "        selected_files_dict (dict): Dictionnaire des fichiers sélectionnés par indice\n",
    "\n",
    "    Returns:\n",
    "        int: Nombre de fichiers déplacés\n",
    "    \"\"\"\n",
    "    # Créer une liste de tous les fichiers sélectionnés\n",
    "    all_selected_files = []\n",
    "    for files in selected_files_dict.values():\n",
    "        all_selected_files.extend(files)\n",
    "\n",
    "    # Liste tous les fichiers dans le répertoire\n",
    "    all_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "    # Créer le répertoire 'noselect' s'il n'existe pas\n",
    "    noselect_dir = os.path.join(directory, \"noselect\")\n",
    "    if not os.path.exists(noselect_dir):\n",
    "        os.makedirs(noselect_dir)\n",
    "\n",
    "    # Déplacer les fichiers non sélectionnés vers le répertoire 'noselect'\n",
    "    files_moved = 0\n",
    "    for filename in all_files:\n",
    "        # Vérifier si le fichier contient un indice (pour éviter de déplacer des fichiers non pertinents)\n",
    "        if re.search(r'tile_(\\d+)_', filename):\n",
    "            if filename not in all_selected_files:\n",
    "                source_path = os.path.join(directory, filename)\n",
    "                target_path = os.path.join(noselect_dir, filename)\n",
    "                shutil.move(source_path, target_path)\n",
    "                files_moved += 1\n",
    "\n",
    "    return files_moved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTION DE VISUALISATION DES LAMES AVEC INSCRIPTION DE LA LOCALISATION DES PETITES LAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listfile = list(Path(totreat_normal_path).glob('*.png'))\n",
    "len(listfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fonction pour visualiser les tuiles de plusieurs lames\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import openslide\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def visualize_tiles_from_global_csv(global_csv_path, slides_dir, output_dir=None, scale_factor=0.):\n",
    "    \"\"\"\n",
    "    Visualise les tuiles de plusieurs lames à partir d'un fichier CSV global.\n",
    "\n",
    "    Args:\n",
    "        global_csv_path (str): Chemin vers le fichier CSV global\n",
    "        slides_dir (str): Répertoire contenant les lames originales\n",
    "        output_dir (str, optional): Répertoire pour sauvegarder les images de visualisation\n",
    "        scale_factor (float, optional): Facteur d'échelle pour réduire l'image originale\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire des images générées par nom de fichier\n",
    "    \"\"\"\n",
    "    # Créer le répertoire de sortie si nécessaire\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Charger le fichier CSV global\n",
    "    df = pd.read_csv(global_csv_path, dtype={'slide_filename': str, 'tile_filename': str})\n",
    "\n",
    "    # Obtenir la liste des fichiers de lames uniques\n",
    "    unique_slides = df['slide_filename'].unique()\n",
    "\n",
    "    # Dictionnaire pour stocker les images générées\n",
    "    generated_images = {}\n",
    "\n",
    "    # Traiter chaque lame\n",
    "    for slide_filename in unique_slides:\n",
    "        print(f\"Visualisation des tuiles pour {slide_filename}...\")\n",
    "\n",
    "        # Filtrer les données pour cette lame\n",
    "        slide_df = df[df['slide_filename'] == slide_filename]\n",
    "\n",
    "        # Rechercher le fichier de lame dans le répertoire\n",
    "        # D'abord, essayer avec le nom exact\n",
    "        slide_filename2 = f\"{slide_filename}.mrxs\"\n",
    "        slide_path = os.path.join(slides_dir, slide_filename2)\n",
    "        print(slide_path)\n",
    "\n",
    "        # Si le fichier n'existe pas avec ce nom exact, rechercher avec des motifs\n",
    "        if not os.path.exists(slides_dir):\n",
    "            print(f\"Fichier {slide_path} non trouvé, recherche d'alternatives...\")\n",
    "\n",
    "            # Extraire le nom de base sans extension\n",
    "            base_name = os.path.splitext(slide_filename)[0]\n",
    "\n",
    "            # Rechercher tous les fichiers potentiels avec un nom similaire\n",
    "            # 1. Essayer avec le nom exact mais différentes extensions\n",
    "            potential_files = []\n",
    "            for ext in ['.svs', '.ndpi', '.tif', '.tiff', '.mrxs']:\n",
    "                potential_files.extend(glob.glob(os.path.join(slides_dir, f\"{base_name}{ext}\")))\n",
    "\n",
    "            # 2. Rechercher avec un 0 au début (pour corriger le problème mentionné)\n",
    "            if not potential_files and not base_name.startswith('0'):\n",
    "                for ext in ['.svs', '.ndpi', '.tif', '.tiff', '.mrxs']:\n",
    "                    potential_files.extend(glob.glob(os.path.join(slides_dir, f\"0{base_name}{ext}\")))\n",
    "\n",
    "            # 3. Rechercher par motif partiel si toujours rien trouvé\n",
    "            if not potential_files:\n",
    "                potential_files = glob.glob(os.path.join(slides_dir, f\"*{base_name}*\"))\n",
    "\n",
    "            if potential_files:\n",
    "                slide_path = potential_files[0]\n",
    "                print(f\"Fichier trouvé: {slide_path}\")\n",
    "            else:\n",
    "                print(f\"Erreur: Aucun fichier correspondant à {slide_filename} trouvé dans {slides_dir}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            # Charger la lame\n",
    "            slide = openslide.OpenSlide(slide_path)\n",
    "            print(slide.dimensions[0])\n",
    "            # Créer une miniature pour la visualisation\n",
    "            l=1024\n",
    "            h=2048\n",
    "            ratio=8\n",
    "            thumbnail = slide.get_thumbnail((ratio*l,ratio*h))  # Ajuster la taille selon l’image\n",
    "            # Convertir en format OpenCV\n",
    "            #thumbnail_np = np.array(thumbnail.convert(\"RGB\"))\n",
    "            #thumbnail_size = (int(slide.dimensions[0] * scale_factor),\n",
    "            #int(slide.dimensions[1] * scale_factor))\n",
    "            #thumbnail = slide.get_thumbnail(thumbnail_size)\n",
    "            visualization_img = np.array(thumbnail)\n",
    "\n",
    "            # Calculer les facteurs d'échelle\n",
    "            scale_x = thumbnail.width / slide.dimensions[0]\n",
    "            scale_y = thumbnail.height / slide.dimensions[1]\n",
    "\n",
    "            # Dessiner toutes les tuiles pour cette lame\n",
    "            for _, row in slide_df.iterrows():\n",
    "                # Coordonnées de la tuile dans l'image originale, converties à l'échelle de visualisation\n",
    "                x, y = int(row['x_original'] * scale_x), int(row['y_original'] * scale_y)\n",
    "                w, h = int(row['width'] * scale_x), int(row['height'] * scale_y)\n",
    "\n",
    "                # Couleur basée sur l'indice du contour\n",
    "                contour_idx = int(row['contour_idx'])\n",
    "                #color = colors[contour_idx % len(colors)]\n",
    "\n",
    "                # Dessiner un rectangle autour de la tuile\n",
    "\n",
    "                cv2.rectangle(visualization_img, (x, y), (x + w, y + h), (0,0,0), thickness=2)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(visualization_img, slide_filename2, (x, y), font, fontScale=0.5, color=(0,0,0),thickness=1 ) #, font_scale, text_color, thickness)\n",
    "            # Sauvegarder l'image si demandé\n",
    "            if output_dir:\n",
    "                base_name = os.path.splitext(os.path.basename(slide_path))[0]\n",
    "                output_path = os.path.join(output_dir, f\"{base_name}_visualization.png\")\n",
    "\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                plt.imshow(visualization_img)\n",
    "                plt.title(f\"Tuiles extraites de {os.path.basename(slide_path)}\")\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(f\"Image sauvegardée: {output_path}\")\n",
    "\n",
    "            # Stocker l'image générée\n",
    "            generated_images[slide_filename] = visualization_img\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la visualisation des tuiles pour {slide_filename}: {e}\")\n",
    "\n",
    "    return generated_images\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    global_csv_path = f\"{train_path}/tumor/all_tiles_coordinates.csv\"\n",
    "    slides_dir = treated_path\n",
    "    output_dir = train_path\n",
    "\n",
    "    images = visualize_tiles_from_global_csv(global_csv_path, slides_dir, output_dir)\n",
    "# Exemple d'utilisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DE FONCTIONNE PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_path = \"/mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/\"\n",
    "import shutil\n",
    "def move_treated(source,target):\n",
    "    try:\n",
    "        output_dir = target\n",
    "        input_dir = source\n",
    "        files = list(Path(input_dir).glob('*.mrxs'))\n",
    "\n",
    "        for file in files:\n",
    "            print(f\"Traitement de la lame {file.stem} ...\")\n",
    "            input_file_mrxs = os.path.join(input_dir,file)\n",
    "            input_file_dir = os.path.join(input_dir,file.stem)\n",
    "            output_file_mrxs = os.path.join(output_dir,file)\n",
    "            output_file_dir = os.path.join(output_dir,file.stem)\n",
    "\n",
    "            shutil.copy2(input_file_mrxs, output_file_mrxs)\n",
    "\n",
    "            # Copier le répertoire\n",
    "            output_file_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Copier tous les éléments du répertoire source\n",
    "            for item in input_file_dir.glob('*'):\n",
    "                item_dest = output_dir / item.name\n",
    "\n",
    "                if item.is_file():\n",
    "                    shutil.copy2(item, item_dest)\n",
    "\n",
    "        print(f\"Répertoire copié avec succès: {input_dir} -> {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la copie du répertoire {input_dir}: {e}\")\n",
    "\n",
    "\n",
    "        print(f\"Fin du copie du ficher : {input_file_mrxs} vers {output_file_dir}\")\n",
    "        print(f\"Fin du copie du ficher : {input_file_dir} vers {output_file_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/',\n",
       " '/mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path, treated_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de la lame RB04065 ...\n",
      "Erreur lors de la copie du répertoire /mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/: '/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/RB04065.mrxs' and '/mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/RB04065.mrxs' are the same file\n",
      "Fin du copie du ficher : /mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/RB04065.mrxs vers /mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/RB04065\n",
      "Fin du copie du ficher : /mnt/c/Users/grego/Documents/Projet_ML/Data/TOTREAT/RB04065 vers /mnt/c/Users/grego/Documents/Projet_ML/Data/TREATED/RB04065\n"
     ]
    }
   ],
   "source": [
    "move_treated(input_path, treated_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des fichiers images et création des matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(train_tumor_path,\"tile_02100_c604_r0_c0.png\")\n",
    "image = Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A TESTER - EXTRAIT DU COURS\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_anap(loading_method):\n",
    "    data_path =\n",
    "    classes = {'normal':0, 'tumor':1}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.png')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "            path = os.path.join(data_path, cl, img)\n",
    "            if os.path.exists(path):\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                imgs.append(np.array(image))\n",
    "                labels.append(i)\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) /6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import to_array\n",
    "img = load_img(f\"{train_path}\"/tumor/xxx.png)\n",
    "x=to_array(img)\n",
    "\n",
    "from tensforflow.keras.utils import image_dataset_from_directory ## voir diff avec flow_from_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramétrage de l'augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Configuration du générateur d'augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    #rescale = 1/255,           #Pas sur que cela soit nécesssaire car déjà scaler\n",
    "    rotation_range=20,        # Rotation aléatoire jusqu'à 20 degrés\n",
    "    width_shift_range=0.2,    # Décalage horizontal jusqu'à 20% de la largeur\n",
    "    height_shift_range=0.2,   # Décalage vertical jusqu'à 20% de la hauteur\n",
    "    #shear_range=0.2,          # Cisaillement (déformation) jusqu'à 20%\n",
    "    zoom_range=0.2,           # Zoom aléatoire entre 80% et 120%\n",
    "    horizontal_flip=True,     # Retournement horizontal aléatoire\n",
    "    fill_mode='nearest')      # Méthode pour remplir les pixels créés après transformation\n",
    "## Datagen du cours\n",
    "#datagen = ImageDataGenerator(\n",
    "#    featurewise_center = False,\n",
    "#    featurewise_std_normalization = False,\n",
    "#    rotation_range = 10,\n",
    "#    width_shift_range = 0.1,\n",
    "#    height_shift_range = 0.1,\n",
    "#    horizontal_flip = True,\n",
    "#    zoom_range = (0.8, 1.2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1024, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Création d'un générateur pour les images d'entraînement\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,  # Dossier parent contenant un sous-dossier par classe\n",
    "    target_size=(512, 1024),        # Redimensionnement des images\n",
    "    batch_size=1,                 # Nombre d'images par lot\n",
    "    class_mode='categorical')      # Type d'encodage des étiquettes (one-hot pour multi-classes)\n",
    "\n",
    "# Création d'un générateur pour les images d'entraînement\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_path,  # Dossier parent contenant un sous-dossier par classe\n",
    "    target_size=(512, 1024),        # Redimensionnement des images\n",
    "    batch_size=1,                 # Nombre d'images par lot\n",
    "    class_mode='categorical')      # Type d'encodage des étiquettes (one-hot pour multi-classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle avec le générateur d'images d'entreinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m20\u001b[0m)  │            \u001b[38;5;34m80\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m15\u001b[0m)  │           \u001b[38;5;34m315\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m15\u001b[0m)  │           \u001b[38;5;34m240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m20\u001b[0m)  │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m20\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │            \u001b[38;5;34m42\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">997</span> (3.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m997\u001b[0m (3.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">997</span> (3.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m997\u001b[0m (3.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregoire/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 720ms/step - accuracy: 0.5462 - loss: 0.6908 - val_accuracy: 0.6667 - val_loss: 0.6589\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 712ms/step - accuracy: 0.6103 - loss: 0.6654 - val_accuracy: 0.6667 - val_loss: 0.6249\n",
      "Epoch 3/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 698ms/step - accuracy: 0.6108 - loss: 0.6539 - val_accuracy: 0.6667 - val_loss: 0.5834\n",
      "Epoch 4/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 676ms/step - accuracy: 0.6788 - loss: 0.6135 - val_accuracy: 1.0000 - val_loss: 0.4894\n",
      "Epoch 5/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 680ms/step - accuracy: 0.8999 - loss: 0.4554 - val_accuracy: 0.9630 - val_loss: 0.3415\n",
      "Epoch 6/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 0.2869 - val_accuracy: 1.0000 - val_loss: 0.1683\n",
      "Epoch 7/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 676ms/step - accuracy: 1.0000 - loss: 0.1592 - val_accuracy: 1.0000 - val_loss: 0.0852\n",
      "Epoch 8/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 678ms/step - accuracy: 1.0000 - loss: 0.0794 - val_accuracy: 1.0000 - val_loss: 0.0498\n",
      "Epoch 9/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 675ms/step - accuracy: 1.0000 - loss: 0.0518 - val_accuracy: 1.0000 - val_loss: 0.0376\n",
      "Epoch 10/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 722ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 0.0236\n"
     ]
    }
   ],
   "source": [
    "# 1ere version d'un modèle en deep uniquement mais pas la bonne manière\n",
    "# Création du modèle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential, models\n",
    "model = tf.keras.Sequential([\n",
    "    # Couches du modèle...\n",
    "    layers.Dense(20, activation='relu', input_shape = (512, 1024,3)),\n",
    "\n",
    "    # Hidden Layers\n",
    "    layers.Dense(15, activation='relu'),\n",
    "    layers.Dense(15, activation='relu'),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "\n",
    "    # Predictive Layer\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    #tf.keras.layers.MaxPool2D(),\n",
    "    layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'BinaryCrossentropy',\n",
    "              #loss='categorical_crossentropy', # en premiere version\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraînement utilisant le générateur d'augmentation\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2eme version d'un modèle en CNN\n",
    "# Création du modèle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential, models\n",
    "model = tf.keras.Sequential([\n",
    "    # CONV LAYERS\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape=(512, 1024, 3)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    ### Flattening\n",
    "    layers.Flatten(),\n",
    "\n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    layers.Dense(128, activation='relu',  kernel_initializer='he_uniform'),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    # PREDICITVE LAYER\n",
    "\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1048576</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">134,217,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1048576\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │   \u001b[38;5;34m134,217,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,505,122</span> (513.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,505,122\u001b[0m (513.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,505,122</span> (513.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,505,122\u001b[0m (513.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraînement utilisant le générateur d'augmentation\n",
    "history_cnn = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS ---\n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].set_ylim((0,3))\n",
    "\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[1].set_ylim((0,1))\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_loss_accuracy(\u001b[43mhistory_cnn\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss_accuracy(history_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot des différentes images convutionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_outputs = [layer.output for layer in model.layers] # same as above\n",
    "activation_model = Model(inputs=model.inputs, outputs=layers_outputs) # model with many outputs !\n",
    "activations = activation_model.predict(X) # 11 predictions at once!\n",
    "[activation.shape for activation in activations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a random triangle\n",
    "image_number = np.random.choice(np.where(y == 1)[0])\n",
    "\n",
    "for layer_number in [0,2,4,6]:\n",
    "\n",
    "    print(f\"--- Observing the effect of the convolutional layer number {layer_number}... ---\")\n",
    "    print(\"\")\n",
    "\n",
    "    temp_number_kernels = model.layers[layer_number].weights[0].shape[-1]\n",
    "    print(f\"{temp_number_kernels} kernels were applied and here are all the activations of this Conv2D Layer:\")\n",
    "\n",
    "    fig, axes = plt.subplots(int(temp_number_kernels/4),4, figsize=(20,7))\n",
    "\n",
    "\n",
    "    for ax, kernel_number in zip(axes.flat,range(temp_number_kernels)):\n",
    "        activation = activations[layer_number][image_number][:, :, kernel_number]\n",
    "        ax.imshow(activation, cmap=\"gray\")\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anapath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
